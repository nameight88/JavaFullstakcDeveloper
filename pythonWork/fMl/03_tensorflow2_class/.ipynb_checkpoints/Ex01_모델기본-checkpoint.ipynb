{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  딥러닝 모델 구동\n",
    "\n",
    "1. model = Sequential() \n",
    "\n",
    "    - 딥러닝의 구조를 짜고 층을 설정하는 부분입니다. \n",
    "\n",
    "2. model.compile() \n",
    "\n",
    "    - 위에서 정해진 모델을 컴퓨터가 알아들을 수 있게끔 컴파일 하는 부분입니다. \n",
    "\n",
    "3. model.fit()\n",
    "\n",
    "    - 모델을 실제로 수행하는 부분입니다. \n",
    "    \n",
    "\n",
    "## (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=30, activation='relu', input_dim=17),\n",
    "    tf.keras.layers.Dense(units=1,  activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./imgs/model1.PNG' width='400'/>\n",
    "\n",
    "- 이제 Dense(30, input_dim=17, activation='relu') 부분을 더 살펴보겠습니다. \n",
    "- 30이라고 되어 있는 것은 이 층에 30개의 노드를 만들겠다는 것입니다. \n",
    "- input_dim이라는 변수가 나옵니다. 이는 입력 데이터에서 몇 개의 값을 가져올지를 정하는 것입니다. \n",
    "- keras는 입력층을 따로 만드는 것이 아니라, 첫 번째 은닉층에 input_dim을 적어 줌으로써 첫 번째 Dense가 은닉층 + 입력층의 역할을 겸합니다. \n",
    "- 우리가 다루고 있는 폐암 수술 환자의 생존 여부 데이터에는 17개의 입력 값들이 있습니다. 따라서 데이터에서 17개의 값을 받아 은닉층의 30개 노드로 보낸다는 뜻입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- model.compile 부분은 앞서 지정한 모델이 효과적으로 구현될 수 있게 여러 가지 환경을 설정해 주면서 컴파일하는 부분입니다. \n",
    "- 먼저 어떤 오차 함수를 사용할지를 정해야 합니다. 여기서는 평균 제곱 오차 함수(mean_squared_error)를 사용했습니다.\n",
    "- 그런데 경우에 따라서는 오차 함수를 바꾸면 더 좋은 효과를 나타내기도 합니다. 오차 함수에는 평균 제곱 오차 계열의 함수 외에도 교차 엔트로피 계열의 함수가 있습니다\n",
    "- 교차 엔트로피는 주로 분류 문제에서 많이 사용되는데, 특별히 예측 값이 참과 거짓 둘 중 하나인 형식일 때는 binary_crossentropy(이항 교차 엔트로피)를 씁니다. 지금 구하고자 하는 것은 생존(1) 또는 사망(0) 둘 중 하나이므로 binary_crossentropy를 사용할 수 있는 좋은 예라고 할 수 있습니다.\n",
    "\n",
    "#### 교차엔트로피\n",
    "<img src='./imgs/model2.PNG' width='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.7576 - accuracy: 0.2409\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 954us/step - loss: 0.5895 - accuracy: 0.4029\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1657 - accuracy: 0.8343\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 932us/step - loss: 0.1564 - accuracy: 0.8436\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1439 - accuracy: 0.8561\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1484 - accuracy: 0.8516\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 997us/step - loss: 0.1557 - accuracy: 0.8443\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1532 - accuracy: 0.8468\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1374 - accuracy: 0.8626\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1299 - accuracy: 0.8701\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1518 - accuracy: 0.8482\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1590 - accuracy: 0.8410\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1739 - accuracy: 0.8261\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1563 - accuracy: 0.8437\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1535 - accuracy: 0.8465\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1390 - accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1408 - accuracy: 0.8592\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 932us/step - loss: 0.1430 - accuracy: 0.8570\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1541 - accuracy: 0.8459\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1306 - accuracy: 0.8694\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1516 - accuracy: 0.8484\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1446 - accuracy: 0.8554\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1490 - accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 932us/step - loss: 0.1514 - accuracy: 0.8486\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1606 - accuracy: 0.8394\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1455 - accuracy: 0.8545\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1562 - accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1556 - accuracy: 0.8444\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1251 - accuracy: 0.8749\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1108 - accuracy: 0.8892\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1185 - accuracy: 0.8815\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1425 - accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1462 - accuracy: 0.8538\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1414 - accuracy: 0.8586\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1547 - accuracy: 0.8453\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1681 - accuracy: 0.8319\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1510 - accuracy: 0.8490\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1527 - accuracy: 0.8473\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1539 - accuracy: 0.8461\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1531 - accuracy: 0.8469\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1517 - accuracy: 0.8483\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1448 - accuracy: 0.8552\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8727\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1230 - accuracy: 0.8770\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1470 - accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1496 - accuracy: 0.8504\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1201 - accuracy: 0.8799\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1357 - accuracy: 0.8643\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1648 - accuracy: 0.8352\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8781\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.8440\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.8463\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1494 - accuracy: 0.8506\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1672 - accuracy: 0.8328\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1381 - accuracy: 0.8619\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1561 - accuracy: 0.8439\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1521 - accuracy: 0.8479\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1307 - accuracy: 0.8693\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1618 - accuracy: 0.8382\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1295 - accuracy: 0.8705\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1290 - accuracy: 0.8710\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1577 - accuracy: 0.8423\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1376 - accuracy: 0.8624\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1345 - accuracy: 0.8655\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1379 - accuracy: 0.8621\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1455 - accuracy: 0.8545\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.1391 - accuracy: 0.8609\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 976us/step - loss: 0.1345 - accuracy: 0.8655\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1790 - accuracy: 0.8210\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 889us/step - loss: 0.1594 - accuracy: 0.8406\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1837 - accuracy: 0.8163\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1383 - accuracy: 0.8617\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 846us/step - loss: 0.1511 - accuracy: 0.8489\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1407 - accuracy: 0.8593\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1202 - accuracy: 0.8798\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1414 - accuracy: 0.8586\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1608 - accuracy: 0.8392\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1399 - accuracy: 0.8601\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1550 - accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1628 - accuracy: 0.8372\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 846us/step - loss: 0.1320 - accuracy: 0.8680\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 802us/step - loss: 0.1496 - accuracy: 0.8504\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1666 - accuracy: 0.8334\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.1141 - accuracy: 0.8859\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 781us/step - loss: 0.1445 - accuracy: 0.8555\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1290 - accuracy: 0.8710\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.1399 - accuracy: 0.8601\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1488 - accuracy: 0.8512\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1619 - accuracy: 0.8381\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1272 - accuracy: 0.8728\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 780us/step - loss: 0.1507 - accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 781us/step - loss: 0.1507 - accuracy: 0.8493\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.1667 - accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.1588 - accuracy: 0.8412\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.1557 - accuracy: 0.8443\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 780us/step - loss: 0.1335 - accuracy: 0.8665\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 781us/step - loss: 0.1733 - accuracy: 0.8267\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 780us/step - loss: 0.1462 - accuracy: 0.8538\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 0.1288 - accuracy: 0.8712\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 0.1602 - accuracy: 0.8398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23edced8ec8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "  \n",
    "# 준비된 수술 환자 데이터를 불러옴\n",
    "Data_set = np.loadtxt(\"./dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
    "  \n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:,17]\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 주어진 폐암 수술 환자의 생존 여부 데이터는 총 470명의 환자에게서 17개의 정보를 정리한 것입니다.\n",
    "+ 각 정보를 ‘속성’이라고 부릅니다. 그리고 생존 여부를 클래스, 가로 한 줄에 해당하는 각 환자의 정보를 각각 ‘샘플’이라고 합니다. \n",
    "+ 주어진 데이터에는 총 470개의 샘플이 각각 17개씩의 속성을 가지고 있는 것입니다.\n",
    "\n",
    "<img src='./imgs/model3.PNG' width='500'/>\n",
    "\n",
    "\n",
    "+ 학습 프로세스가 모든 샘플에 대해 한 번 실행되는 것을 1 epoch(‘에포크’라고 읽습니다)라고 합니다. \n",
    "+ 코드에서 epochs=100으로 지정한 것은 각 샘플이 처음부터 끝까지 100번 재사용될 때까지 실행을 반복하라는 뜻입니다.\n",
    "\n",
    "+ batch_size는 샘플을 한 번에 몇 개씩 처리할지를 정하는 부분으로 batch_size=10은 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻이 됩니다. \n",
    "+ batch_size가 너무 크면 학습 속도가 느려지고, 너무 작으면 각 실행 값의 편차가 생겨서 전체 결괏값이 불안정해질 수 있습니다. 따라서 자신의 컴퓨터 메모리가 감당할 만큼의 batch_size를 찾아 설정해 주는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (4) 결과\n",
    "\n",
    "+ 정확도(accuracy) 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 998us/step - loss: 0.1489 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8510638475418091"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 출력\n",
    "test_loss, test_accuracy = model.evaluate(X, Y)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (5) 예측\n",
    "\n",
    "+ 마지막 데이타로 확인\n",
    "\n",
    "447\t8\t5.2\t4.1\t0\t0\t0\t0\t0\t0\t12\t0\t0\t0\t0\t0\t49               0 (사망)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0044537e-19]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_x = [[447,8,5.2,4.1,0,0,0,0,0,0,12,0,0,0,0,0,49]]\n",
    "model.predict(pre_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측결과\n",
    "\n",
    "0.028은 0에 가까움"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
