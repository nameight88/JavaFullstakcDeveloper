{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 MNIST\n",
    "\n",
    "+ mnist : 머신러닝의 고전적인 문제로 숫자를 손으로 쓴 글자를 모아놓은 데이터세트\n",
    "+ 손글씨 mnist : 0~9까지 숫자 28*28 픽셀의 이미지 데이타세트\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# (1) MNIST 데이터셋 불러오기\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "# 데이타 수 확인\n",
    "print(len(train_X), len(test_X))\n",
    "\n",
    "# 데이타 형태 확인\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 확인\n",
    "#      imshow() : 이미지를 그래프 형태로 표시\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_X[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(train_Y[0])  # 정답(라벨)을 확인 ( 숫자 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# (3) 데이터 정규화\n",
    "train_X = train_X / 255.0\n",
    "test_X = test_X / 255.0\n",
    "\n",
    "print(train_X[0])\n",
    "# [결과] 모든 데이타가 0~1 사이의 값을 되도록 정규화가 잘 되었음을 확인\n",
    "\n",
    "# 앞에서 to_categorical() 를 이용하여 one-hot encoding 작업을 했었는데 \n",
    "# 10개의 답을 위해 [1 0 0 0 0 0 0 0 0 0] 으로 계산하는 것이 오히려 더 시스템 낭비일 수가 있다.\n",
    "# 그래서 희소행렬을 이용하는데 categorical_crossentropy 손실율 계산시 sparse_categorical_crossentropy를 사용하여\n",
    "# 데이타 전처리 없이 희소 행렬을 나타내는 데이타를 정답 행렬로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten\n",
    "\n",
    "   + 이차원 배열을 일차원 배열로 바꿔주는 함수\n",
    "   + 컨볼루션 층(Convolution layer)나 맥스플링(MaxPooling)은 주어진 이미지를 2차원 배열인 채로 다룬다.\n",
    "     그 뒤 일반층으로 넘길 때 Flatten() 함수를 이용한다\n",
    "\n",
    "\n",
    "## 활성화 함수 (Activation Function)\n",
    "\n",
    "   + 입력을 비선형 출력으로 변환해주는 함수\n",
    "   + 자주 사용되는 활성화 함수\n",
    "       - 시그모이드 (sigmoid)\n",
    "       - 하이퍼볼릭 탄젠트 (tanh)\n",
    "       - ReLU\n",
    "       \n",
    "       [공식문서] https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "\n",
    "       \n",
    "## 입력과 출력\n",
    "\n",
    "   + 첫번째 레이어는 입력 데이터 형태로 이미지의 가로, 세로 배열값으로 input_shape=(28,28)\n",
    "   + 마지막 레이어는 출력층으로 반드시 분류해야하는 클래스 수와 동일해야 함\n",
    "       - mnist는 0~9까지 총 10개의 분류값(클래스)로 되어 있기에 출력층 노드는 10이여야 함\n",
    "       - 출력층의 노드가 1개인 경우는 sigmoid 활성화 함수를 적용하지만\n",
    "           - tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "       - 출력층의 노드가 2개 이상인 경우는 softmax 활성화 함수를 적용한다.\n",
    "           - tf.keras.layers.Dense(units=2, activation='softmax')\n",
    "           \n",
    "           \n",
    "## 손실함수        \n",
    "\n",
    "   + 모델의 출력층에 따라 손실함수를 설정해야 정상적인 훈련이 가능\n",
    "   + compile() 함수에 loss지정\n",
    "    \n",
    "    \n",
    "   + 이진분류 : 출력층의 노드 = 1, sigmoid 활성화 함수\n",
    "        - model.compile(loss='binary_crossentropy')\n",
    "        \n",
    "        \n",
    "   + 출력층의 노드 = 2개 이상, softmax 활성화 함수\n",
    "        - model.compile(loss='categorical_crossentropy' ) : 출력 데이타(y)가 one-hot vector인 경우\n",
    "        - model.compile(loss='sparse_categorical_crossentropy' ) : 출력 데이타(y)가 one-hot vector가 아닌 경우\n",
    "        - mnist 데이타는 클래스의 수가 10개로 원핫벡터가 아니라 0~9까지 레이블 값을 가진다\n",
    "        \n",
    "         [참고] one-hot vector : [0,0,1,0,0,0,0,0,0,0]\n",
    "     \n",
    "\n",
    "## 옵티마이저 (optimizer )\n",
    "\n",
    "   + 손실을 낮추기 위해 신경망의 가중치 같은 속성 변경하는데 사용되는 최적화 방법\n",
    "   + 일반적으로 많이 사용하는 알고리즘 : Adam\n",
    "   + 케라스에서 지원하는 옵티마이저 :\n",
    "       -   SGD, Adam, Adgrad, Nadam, RMRprop, Adadelta, Adamax, Ftrl   \n",
    "       \n",
    "          [공식문서] https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "   \n",
    "   \n",
    "      + 클래스 인스턴스로 지정 \n",
    "           - adam = tf.keras.optimizers.Adam(lr=0.001)\n",
    "             model.compile(optimizer=adam)\n",
    "           - lr (Learning rate:학습률) 같은 하이퍼파라미터르 직접 지정 가능\n",
    "           \n",
    "      + 문자열 지정 (전부 소문자임 )\n",
    "           - model.compile(optimizer='adam')\n",
    "           \n",
    "           \n",
    "## 평가지표 (metrics)\n",
    "\n",
    "   + 분류모델에 대한 평가지표는 정확도를 나탸내는 'accurary' 또는 'acc'가 많이 사용\n",
    "   + 'auc', 'precision', 'recall' 등의 지표도 사용\n",
    "   \n",
    "       [공식문서] https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (4) MNIST 분류 모델\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델을 변경해서 해본다면?\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "#     tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# 희소행렬 : categorical_crossentropy -> sparse_categorical_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 ( 훈련 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2969 - accuracy: 0.9162 - val_loss: 0.1663 - val_accuracy: 0.9539\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1322 - accuracy: 0.9625 - val_loss: 0.1277 - val_accuracy: 0.9626\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.9735 - val_loss: 0.1277 - val_accuracy: 0.9629\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.0994 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.1003 - val_accuracy: 0.9712\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9882 - val_loss: 0.1027 - val_accuracy: 0.9721\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0987 - val_accuracy: 0.9721\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.1063 - val_accuracy: 0.9729\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.1158 - val_accuracy: 0.9695\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1111 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "# (5) MNIST 분류 모델 학습\n",
    "history = model.fit(train_X, train_Y, epochs=10, validation_split=0.25)\n",
    "\n",
    "# [결과]\n",
    "# 훈련 데이터의 정확도가 점점 증가하는 것에 비해 검증 데이타의 정확도는 일정 수준으로 유지되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 \n",
    "\n",
    "   + 모델 성능을 검증하고 평가\n",
    "   + 컴파일 단계에서 지정한 손실과 정확도를 순서대로 반환하여 출력\n",
    "   \n",
    "   \n",
    "[참고] 모델을 다시 변경하여 수행한다면???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9736\n",
      "------------------------------------------------\n",
      "Test loss: 0.09118741750717163\n",
      "Test accuracy: 0.9735999703407288\n"
     ]
    }
   ],
   "source": [
    "# (7) MNIST 분류 모델 평가\n",
    "score = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# [결과]\n",
    "#  테스트 데이타에 대한 평가 정확도는 88%이다.\n",
    "#  모델을 바꾸면 정확도가 달라진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 - 작성한 이미지 판단하기\n",
    "\n",
    "    - 그림판에서 정사각형 크기(동일 픽셀)를 만들고 검정색 굵은 선으로 숫자를 그리고 'my.png'로 저장한다\n",
    "      ( 직접 손글씨 이미지 만들기  ( 200px * 200px ) )\n",
    "      \n",
    "    - open cv를 이용하여 이미지를 픽셀데이타로 변경한다\n",
    "    \n",
    "* open cv\n",
    "    - https://opencv.org\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[ 참고 ] opencv 관련\n",
    "\n",
    "- https://opencv-python.readthedocs.io/en/latest/doc/08.imageProcessing/imageProcessing.html\n",
    "\n",
    "- https://076923.github.io/posts/Python-opencv-10/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv 인스톨\n",
    "# !pip install opencv-python\n",
    "\n",
    "# 그림판에서 숫자를 그리고 28*28 픽셀로  img 폴더 아래 my.png 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def predict_digit(filename):\n",
    "\n",
    "    # 직접 그린 손글씨 이미지 읽어 들이기\n",
    "    my_img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # 이미지 데이터를 학습에 적합하게 변환하기\n",
    "    my_img = cv2.cvtColor(my_img, cv2.COLOR_BGR2GRAY)   \n",
    "    \n",
    "    my_img = cv2.resize(my_img, (28, 28))\n",
    "    #print(my_img)\n",
    "    \n",
    "    my_img = 783 - my_img # // 256 # 흑백 반전 0-> 15, 1->14, 10 -> 5, 3->12 \n",
    "    #print(my_img)\n",
    "    \n",
    "    # 2차원 배열을 1차원 배열로 변환하기\n",
    "    my_img = my_img.reshape((-1, 784))\n",
    "    # 데이터 예측하기\n",
    "    res = model.predict(my_img)\n",
    "    # print(res)\n",
    "    return res[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "my.png = [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 이미지 파일을 지정해서 실행하기\n",
    "n = predict_digit(\"imgdata/my.png\")\n",
    "print(\"my.png = \" + str(n))\n",
    "\n",
    "# [결과] 7인데 5라고 예측하네 ㅡ.ㅡ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
